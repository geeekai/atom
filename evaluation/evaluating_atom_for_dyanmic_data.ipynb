{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    " \n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the LLM models and the necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_mistralai import ChatMistralAI\n",
    "from langchain_mistralai import MistralAIEmbeddings\n",
    "\n",
    "mistral_api_key = \"##\"\n",
    "mistral_llm_model = ChatMistralAI(\n",
    "    api_key = mistral_api_key,\n",
    "    model=\"mistral-large-latest\",\n",
    "    temperature=0,\n",
    "    max_retries=2,\n",
    ")\n",
    "\n",
    "\n",
    "mistral_embeddings_model = MistralAIEmbeddings(\n",
    "    model=\"mistral-embed\",\n",
    "    api_key = mistral_api_key\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "\n",
    "openai_api_key = \"##\"\n",
    "\n",
    "openai_llm_model = ChatOpenAI(\n",
    "    api_key = openai_api_key,\n",
    "    model=\"gpt4o-mini\",\n",
    "    #temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    ")\n",
    "\n",
    "openai_embeddings_model = OpenAIEmbeddings(\n",
    "    api_key = openai_api_key ,\n",
    "    model=\"text-embedding-3-large\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from atom.utils import LangchainOutputParser\n",
    "\n",
    "lg = LangchainOutputParser(llm_model=openai_llm_model, embeddings_model=openai_embeddings_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_tweets = pd.read_excel(\"../datasets/llms_history_and_openai_posts/france_covid_history.xlsx\")\n",
    "llms_history = pd.read_excel(\"../datasets/llms_history_and_openai_posts/llms_history.xlsx\")\n",
    "france_covid_history = pd.read_excel(\"../datasets/llms_history_and_openai_posts/france_covid_history.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting triplets and factoids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from atom.utils import Factoid\n",
    "\n",
    "async def extract_factoids(batch):\n",
    "\n",
    "    factoids = await lg.extract_information_as_json_for_context(output_data_structure=Factoid, contexts=batch)\n",
    "\n",
    "    return [factoid.phrase for factoid in factoids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of batches: 1\n"
     ]
    }
   ],
   "source": [
    "openai_tweets[\"factoids\"] = await extract_factoids(openai_tweets[\"Tweet\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the TKG\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from atom import Atom\n",
    "\n",
    "atom = Atom(llm_model=openai_llm_model, embeddings_model=openai_embeddings_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast \n",
    "\n",
    "def to_dictionary(df): \n",
    "\n",
    "    if isinstance(df['factoids'][0], str):\n",
    "        df[\"factoids\"] = df[\"factoids\"].apply(lambda x:ast.literal_eval(x))\n",
    "    grouped_df = df.groupby(\"observation date\")[\"factoids\"].sum().reset_index()\n",
    "    return {\n",
    "        str(date): factoids for date, factoids in grouped_df.set_index(\"observation date\")[\"factoids\"].to_dict().items()\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "llms_history_dict = to_dictionary(llms_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'30-12-2017': ['Google researchers introduced the Transformer architecture on June 12, 2017.',\n",
       "  \"The paper 'Attention Is All You Need' was released on June 12, 2017.\",\n",
       "  'The Transformer architecture revolutionized natural language processing on June 12, 2017.',\n",
       "  'The Transformer architecture enables models to process data more efficiently through self-attention mechanisms.'],\n",
       " '30-12-2018': ['OpenAI released GPT-1 on June 11, 2018.',\n",
       "  'GPT-1 is the first Generative Pre-trained Transformer model.',\n",
       "  'GPT-1 demonstrated the effectiveness of unsupervised pre-training for language understanding tasks.',\n",
       "  'Google introduced BERT on October 11, 2018.',\n",
       "  'BERT stands for Bidirectional Encoder Representations from Transformers.',\n",
       "  'BERT is a transformer-based model.',\n",
       "  'BERT achieved state-of-the-art results on various NLP benchmarks.',\n",
       "  'BERT understands context from both directions.'],\n",
       " '30-12-2019': ['OpenAI announced GPT-2 on February 14, 2019.',\n",
       "  'GPT-2 is a significantly larger and more powerful version of its predecessor.',\n",
       "  'GPT-2 is capable of generating coherent and contextually relevant text.',\n",
       "  'OpenAI initially withheld the full model release of GPT-2 due to concerns about potential misuse.'],\n",
       " '30-12-2020': ['OpenAI unveiled GPT-3 on May 28, 2020.',\n",
       "  'GPT-3 is a model with 175 billion parameters.',\n",
       "  'GPT-3 demonstrated remarkable abilities in natural language understanding.',\n",
       "  'GPT-3 demonstrated remarkable abilities in natural language generation.',\n",
       "  'GPT-3 set new benchmarks in NLP tasks.'],\n",
       " '30-12-2022': ['DeepMind introduced Gato on May 5, 2022.',\n",
       "  'Gato is a multimodal model.',\n",
       "  'Gato was trained on 604 tasks.',\n",
       "  'The tasks include image captioning and dialogue.',\n",
       "  'Gato showcases versatility across various domains.',\n",
       "  'OpenAI launched ChatGPT on November 30, 2022.',\n",
       "  'ChatGPT is a conversational AI based on GPT-3.',\n",
       "  'ChatGPT gained popularity for its human-like responses.',\n",
       "  'ChatGPT has wide-ranging applications.'],\n",
       " '30-12-2023': ['OpenAI released GPT-4 on March 14, 2023.',\n",
       "  'GPT-4 is praised for its increased accuracy.',\n",
       "  'GPT-4 has multimodal capabilities allowing it to process both text and images.',\n",
       "  'DeepMind announced Gemini on June 13, 2023.',\n",
       "  'Gemini is a multimodal large language model.',\n",
       "  'Gemini is designed to challenge models like GPT-4.',\n",
       "  'Gemini integrates advanced reasoning and planning abilities.'],\n",
       " '30-12-2024': ['Google released Gemma on February 21, 2024.',\n",
       "  'Gemma is a collection of open-source LLMs.',\n",
       "  'Gemma is available in various sizes.',\n",
       "  'Gemma is trained on up to 6 trillion tokens.',\n",
       "  'Gemma aims to make advanced AI models more accessible.',\n",
       "  'DeepMind introduced SIMA on March 15, 2024.',\n",
       "  'SIMA is an AI agent capable of understanding natural language instructions across various 3D virtual environments on March 15, 2024.',\n",
       "  'SIMA demonstrates adaptability without retraining.',\n",
       "  'Anthropic released Claude 3.5 Sonnet on June 18, 2024.',\n",
       "  'Claude 3.5 Sonnet is an improved LLM.',\n",
       "  'Claude 3.5 Sonnet demonstrates enhanced performance in coding.',\n",
       "  'Claude 3.5 Sonnet demonstrates enhanced performance in multistep workflows.',\n",
       "  'Claude 3.5 Sonnet demonstrates enhanced performance in image analysis.',\n",
       "  'Claude 3.5 Sonnet surpasses previous models.'],\n",
       " '30-12-2025': ['DeepSeek released DeepSeek-R1 on January 10, 2025.',\n",
       "  'DeepSeek-R1 is a 671-billion-parameter open-weight model.',\n",
       "  'DeepSeek-R1 performs comparably to other leading models.',\n",
       "  'DeepSeek-R1 has a significantly lower cost compared to other leading models.',\n",
       "  'DeepSeek-R1 highlights advancements in cost-effective LLM training.',\n",
       "  'Google launched PaliGemma 2 Mix on February 12, 2025.',\n",
       "  'PaliGemma 2 Mix is an upgraded vision-language model.',\n",
       "  'PaliGemma 2 Mix is fine-tuned for multiple tasks.',\n",
       "  'PaliGemma 2 Mix is available in various parameter sizes and resolutions.',\n",
       "  'PaliGemma 2 Mix enhances multimodal AI capabilities.']}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llms_history_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] ------- Extracting Triplets\n",
      "Total number of batches: 1\n",
      "[INFO] ------- Extracting Triplets\n",
      "Total number of batches: 1\n",
      "[INFO] ------- Extracting Triplets\n",
      "Total number of batches: 1\n",
      "[INFO] ------- Extracting Triplets\n",
      "Total number of batches: 1\n",
      "[INFO] ------- Extracting Triplets\n",
      "Total number of batches: 1\n",
      "[INFO] ------- Extracting Triplets\n",
      "Total number of batches: 1\n",
      "[INFO] ------- Extracting Triplets\n",
      "Total number of batches: 1\n",
      "[INFO] ------- Extracting Triplets\n",
      "Total number of batches: 1\n",
      "[INFO] ------- Building Atomic KGs\n",
      "[INFO] ------- Adding Source Context to Atomic KGs\n",
      "[INFO] ------- Merging Atomic KGs\n",
      "[INFO] Wohoo! Entity was matched --- [gpt 2:model] --merged --> [gpt 2:product] (score=0.88)\n",
      "[INFO] Wohoo! Entity was matched --- [gpt 2:model] --merged --> [gpt 2:algorithm] (score=0.86)\n",
      "[INFO] Exact match for Entity: openai\n",
      "[INFO] Wohoo! Entity was matched --- [gpt 2:algorithm] --merged --> [gpt 2:product] (score=0.85)\n",
      "[INFO] ------- Adding Timestamps to Relationships\n",
      "[INFO] ------- Building Atomic KGs\n",
      "[INFO] ------- Building Atomic KGs\n",
      "[INFO] ------- Building Atomic KGs\n",
      "[INFO] ------- Building Atomic KGs\n",
      "[INFO] ------- Building Atomic KGs\n",
      "[INFO] ------- Building Atomic KGs\n",
      "[INFO] ------- Adding Source Context to Atomic KGs\n",
      "[INFO] ------- Merging Atomic KGs\n",
      "[INFO] Exact match for Entity: transformer architecture\n",
      "[INFO] Exact match for Entity: transformer architecture\n",
      "[INFO] ------- Adding Timestamps to Relationships\n",
      "[INFO] ------- Adding Source Context to Atomic KGs\n",
      "[INFO] ------- Merging Atomic KGs\n",
      "[INFO] Wohoo! Entity was matched --- [chatgpt:software] --merged --> [chatgpt:technology] (score=0.90)\n",
      "[INFO] Wohoo! Entity was matched --- [chatgpt:ai] --merged --> [chatgpt:product] (score=0.82)\n",
      "[INFO] Wohoo! Entity was matched --- [gato:model] --merged --> [gato:product] (score=0.88)\n",
      "[INFO] Wohoo! Entity was matched --- [gato:system] --merged --> [gato:model] (score=0.85)\n",
      "[INFO] Wohoo! Entity was matched --- [chatgpt:product] --merged --> [chatgpt:technology] (score=0.86)\n",
      "[INFO] Wohoo! Entity was matched --- [gato:model] --merged --> [gato:product] (score=0.88)\n",
      "[INFO] ------- Adding Timestamps to Relationships\n",
      "[INFO] ------- Adding Source Context to Atomic KGs\n",
      "[INFO] ------- Merging Atomic KGs\n",
      "[INFO] Exact match for Entity: gpt 3\n",
      "[INFO] Wohoo! Relation --- [demonstrated] -- exists already in the global relationships\n",
      "[INFO] Wohoo! Entity was matched --- [gpt 3:model] --merged --> [gpt 3:technology] (score=0.84)\n",
      "[INFO] Wohoo! Entity was matched --- [gpt 3:technology] --merged --> [gpt 3:algorithm] (score=0.87)\n",
      "[INFO] Exact match for Entity: gpt 3\n",
      "[INFO] ------- Adding Timestamps to Relationships\n",
      "[INFO] ------- Building Atomic KGs\n",
      "[INFO] ------- Adding Source Context to Atomic KGs\n",
      "[INFO] ------- Merging Atomic KGs\n",
      "[INFO] Wohoo! Entity was matched --- [gpt 1:model] --merged --> [gpt 1:software] (score=0.85)\n",
      "[INFO] Wohoo! Entity was matched --- [bert:methodology] --merged --> [bert:algorithm] (score=0.85)\n",
      "[INFO] Wohoo! Entity was matched --- [bert:model] --merged --> [bert:acronym] (score=0.81)\n",
      "[INFO] Exact match for Entity: bert\n",
      "[INFO] Wohoo! Entity was matched --- [bert:algorithm] --merged --> [bert:acronym] (score=0.84)\n",
      "[INFO] Wohoo! Entity was matched --- [gpt 1:model] --merged --> [gpt 1:software] (score=0.85)\n",
      "[INFO] ------- Adding Timestamps to Relationships\n",
      "[INFO] ------- Adding Source Context to Atomic KGs\n",
      "[INFO] ------- Merging Atomic KGs\n",
      "[INFO] Wohoo! Entity was matched --- [gemma:collection] --merged --> [gemma:product] (score=0.86)\n",
      "[INFO] Wohoo! Entity was matched --- [gemma:algorithm] --merged --> [gemma:product] (score=0.85)\n",
      "[INFO] Exact match for Entity: claude 3.5 sonnet\n",
      "[INFO] Wohoo! Entity was matched --- [claude 3.5 sonnet:llm] --merged --> [claude 3.5 sonnet:product] (score=0.80)\n",
      "[INFO] Wohoo! Entity was matched --- [enhanced performance:performance] --merged --> [enhanced performance in coding:performance] (score=0.89)\n",
      "[INFO] Wohoo! Entity was matched --- [sima:algorithm] --merged --> [sima:agent] (score=0.84)\n",
      "[INFO] Wohoo! Relation --- [demonstrates] -- exists already in the global relationships\n",
      "[INFO] Wohoo! Entity was matched --- [claude 3.5 sonnet:model] --merged --> [claude 3.5 sonnet:algorithm] (score=0.84)\n",
      "[INFO] Exact match for Entity: gemma\n",
      "[INFO] Exact match for Entity: claude 3.5 sonnet\n",
      "[INFO] Wohoo! Entity was matched --- [enhanced performance:performance] --merged --> [enhanced performance in coding:performance] (score=0.89)\n",
      "[INFO] Wohoo! Relation --- [demonstrates] -- exists already in the global relationships\n",
      "[INFO] Wohoo! Entity was matched --- [sima:agent] --merged --> [sima:technology] (score=0.81)\n",
      "[INFO] Wohoo! Entity was matched --- [gemma:organization] --merged --> [gemma:product] (score=0.84)\n",
      "[INFO] Wohoo! Entity was matched --- [claude 3.5 sonnet:product] --merged --> [claude 3.5 sonnet:algorithm] (score=0.83)\n",
      "[INFO] Wohoo! Relation --- [released] -- exists already in the global relationships\n",
      "[INFO] Wohoo! Relation --- [demonstrates] -- exists already in the global relationships\n",
      "[INFO] ------- Adding Timestamps to Relationships\n",
      "[INFO] ------- Adding Source Context to Atomic KGs\n",
      "[INFO] ------- Merging Atomic KGs\n",
      "[INFO] Exact match for Entity: gpt 4\n",
      "[INFO] Exact match for Entity: gemini\n",
      "[INFO] Wohoo! Entity was matched --- [gemini:algorithm] --merged --> [gemini:model] (score=0.85)\n",
      "[INFO] Exact match for Entity: gpt 4\n",
      "[INFO] Wohoo! Entity was matched --- [gemini:model] --merged --> [gemini:product] (score=0.88)\n",
      "[INFO] ------- Adding Timestamps to Relationships\n",
      "[INFO] ------- Adding Source Context to Atomic KGs\n",
      "[INFO] ------- Merging Atomic KGs\n",
      "[INFO] Exact match for Entity: deepseek r1\n",
      "[INFO] Exact match for Entity: other leading models\n",
      "[INFO] Exact match for Entity: paligemma 2 mix\n",
      "[INFO] Wohoo! Entity was matched --- [deepseek r1:model] --merged --> [deepseek r1:product] (score=0.87)\n",
      "[INFO] Wohoo! Entity was matched --- [paligemma 2 mix:algorithm] --merged --> [paligemma 2 mix:model] (score=0.85)\n",
      "[INFO] Wohoo! Entity was matched --- [deepseek r1:product] --merged --> [deepseek r1:model] (score=0.87)\n",
      "[INFO] Wohoo! Entity was matched --- [paligemma 2 mix:product] --merged --> [paligemma 2 mix:model] (score=0.87)\n",
      "[INFO] Wohoo! Entity was matched --- [paligemma 2 mix:product] --merged --> [paligemma 2 mix:model] (score=0.87)\n",
      "[INFO] Wohoo! Entity was matched --- [deepseek r1:methodology] --merged --> [deepseek r1:model] (score=0.83)\n",
      "[INFO] ------- Adding Timestamps to Relationships\n",
      "[INFO] Exact match for Entity: openai\n",
      "[INFO] Exact match for Entity: deepmind\n",
      "[INFO] Exact match for Entity: openai\n",
      "[INFO] Exact match for Entity: google\n",
      "[INFO] Wohoo! Entity was matched --- [gpt 4:model] --merged --> [gpt 3:model] (score=0.84)\n",
      "[INFO] Wohoo! Relation --- [released] -- exists already in the global relationships\n",
      "[INFO] Wohoo! Relation --- [introduced] -- exists already in the global relationships\n",
      "[INFO] Wohoo! Entity was matched --- [other leading models:model] --merged --> [previous models:model] (score=0.85)\n",
      "[INFO] Wohoo! Relation --- [released] -- exists already in the global relationships\n",
      "[INFO] Wohoo! Relation was matched --- [available_in] --merged --> [is_available_in] \n",
      "[INFO] Wohoo! Relation was matched --- [available_in] --merged --> [is_available_in] \n",
      "[INFO] Wohoo! Relation --- [pertains_to] -- exists already in the global relationships\n",
      "[INFO] Exact match for Entity: openai\n",
      "[INFO] Wohoo! Entity was matched --- [nlp benchmarks:benchmark] --merged --> [new benchmarks:benchmark] (score=0.82)\n",
      "[INFO] Wohoo! Entity was matched --- [language understanding tasks:task] --merged --> [nlp tasks:task] (score=0.86)\n",
      "[INFO] Exact match for Entity: deepmind\n",
      "[INFO] Wohoo! Relation --- [launched] -- exists already in the global relationships\n",
      "[INFO] Wohoo! Relation --- [introduced] -- exists already in the global relationships\n",
      "[INFO] Wohoo! Relation --- [is_model] -- exists already in the global relationships\n",
      "[INFO] Wohoo! Relation --- [trained_on] -- exists already in the global relationships\n",
      "[INFO] Wohoo! Relation was matched --- [applies_to] --merged --> [applies_in] \n",
      "[INFO] Wohoo! Relation --- [released] -- exists already in the global relationships\n",
      "[INFO] Exact match for Entity: openai\n",
      "[INFO] Exact match for Entity: google\n",
      "[INFO] Wohoo! Entity was matched --- [gpt 3:model] --merged --> [gpt 3:algorithm] (score=0.86)\n",
      "[INFO] Wohoo! Entity was matched --- [previous models:model] --merged --> [models:model] (score=0.83)\n",
      "[INFO] Wohoo! Relation --- [released] -- exists already in the global relationships\n",
      "[INFO] Wohoo! Relation was matched --- [demonstrates] --merged --> [demonstrated] \n",
      "[INFO] Wohoo! Relation was matched --- [demonstrates] --merged --> [demonstrated] \n",
      "[INFO] Wohoo! Relation was matched --- [demonstrates] --merged --> [demonstrated] \n",
      "[INFO] Wohoo! Relation --- [introduced] -- exists already in the global relationships\n",
      "[INFO] Wohoo! Relation --- [released] -- exists already in the global relationships\n",
      "[INFO] Wohoo! Relation --- [understands] -- exists already in the global relationships\n",
      "[INFO] Wohoo! Relation was matched --- [demonstrates] --merged --> [demonstrated] \n",
      "[INFO] Wohoo! Relation --- [released] -- exists already in the global relationships\n",
      "[INFO] Wohoo! Relation --- [is_based_on] -- exists already in the global relationships\n",
      "[INFO] Wohoo! Relation --- [introduced] -- exists already in the global relationships\n",
      "[INFO] Wohoo! Relation --- [released] -- exists already in the global relationships\n",
      "[INFO] Wohoo! Relation --- [announced] -- exists already in the global relationships\n"
     ]
    }
   ],
   "source": [
    "kg_llms_mini_3= await atom.build_graph_from_different_obs_times(atomic_facts_with_obs_timestamps=llms_history_dict, rel_threshold=0.7, ent_threshold=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Draw the graph\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final section involves visualizing the constructed knowledge graph using GraphIntegrator. The graph database Neo4j is accessed using specified credentials, and the resulting graph is visualized to provide a visual representation of the relationships and entities extracted from the document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from atom.graph_integration import GraphIntegrator\n",
    "\n",
    "\n",
    "URI = \"bolt://localhost:7687\"\n",
    "USERNAME = \"neo4j\"\n",
    "PASSWORD = \"##\"\n",
    "\n",
    "GraphIntegrator(uri=URI, username=USERNAME, password=PASSWORD).visualize_graph(knowledge_graph=kg_llms_mini_3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-itext2kg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

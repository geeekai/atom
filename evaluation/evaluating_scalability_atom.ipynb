{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    " \n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the LLM models and the necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "\n",
    "openai_api_key = \"##\"\n",
    "\n",
    "openai_llm_model = ChatOpenAI(\n",
    "    api_key = openai_api_key,\n",
    "    model=\"gpt-4o\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    ")\n",
    "\n",
    "openai_embeddings_model = OpenAIEmbeddings(\n",
    "    api_key = openai_api_key ,\n",
    "    model=\"text-embedding-3-large\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from atom.utils import LangchainOutputParser\n",
    "\n",
    "lg = LangchainOutputParser(llm_model=openai_llm_model, embeddings_model=openai_embeddings_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "def recover_list_dfs(df):\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == object:  # Ensure we only process object (string) columns\n",
    "            first_valid_index = df[col].first_valid_index()\n",
    "            if first_valid_index is not None and isinstance(df[col].loc[first_valid_index], str):\n",
    "                first_value = df[col].loc[first_valid_index].strip()  # Strip any whitespace\n",
    "                if first_value.startswith(\"[\") and first_value.endswith(\"]\"):  # Ensure it's a list format\n",
    "                    def safe_eval(x):\n",
    "                        try:\n",
    "                            return ast.literal_eval(x) if isinstance(x, str) else x\n",
    "                        except (SyntaxError, ValueError) as e:\n",
    "                            print(f\"Skipping invalid value in column '{col}': {x} -> {e}\")\n",
    "                            return None  # Return None for problematic values\n",
    "                    df[col] = df[col].apply(safe_eval)\n",
    "                    \n",
    "    return df\n",
    "    \n",
    "\n",
    "df_news = recover_list_dfs(pd.read_excel(\"../datasets/news/df_news_all_llms_eval.xlsx\"))\n",
    "df_abstracts = recover_list_dfs(pd.read_excel(\"../datasets/abstracts/df_abstracts_all_llms_eval.xlsx\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "from itertools import chain\n",
    "\n",
    "factoids = list(chain(*[ast.literal_eval(fact) for fact in df_news[\"factoids_ground_truth\"]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "387"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(factoids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating the latency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from atom import Atom\n",
    "\n",
    "atom = Atom(llm_model=openai_llm_model, embeddings_model=openai_embeddings_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "async def calculate_latency(factoids: list[str]):\n",
    "    results = []\n",
    "    current_date = str(datetime.now().date())\n",
    "    for i in range(1, len(factoids), 20):\n",
    "        try:\n",
    "            start = time.perf_counter()\n",
    "            await atom.build_graph(atomic_facts=factoids[:i], obs_timestamp=current_date)\n",
    "            end = time.perf_counter()\n",
    "            elapsed_time = end - start\n",
    "            results.append({\"number of factoids\": i, \"atom's execution time\": elapsed_time})\n",
    "        except Exception as e:\n",
    "            # Retry once after error\n",
    "            print(f\"Error processing {i} factoids on first attempt: {e}. Retrying...\")\n",
    "            try:\n",
    "                start = time.perf_counter()\n",
    "                await atom.build_graph(atomic_facts=factoids[:i], obs_timestamp=current_date)\n",
    "                end = time.perf_counter()\n",
    "                elapsed_time = end - start\n",
    "                results.append({\"number of factoids\": i, \"atom's execution time\": elapsed_time})\n",
    "            except Exception as e_retry:\n",
    "                # If retry fails, log the error and continue\n",
    "                print(f\"Error processing {i} factoids on retry: {e_retry}. Skipping...\")\n",
    "                results.append({\"number of factoids\": i, \"atom's execution time\": None, \"error\": str(e_retry)})\n",
    "        finally:\n",
    "            # Save progress after each iteration\n",
    "            pd.DataFrame(results).to_excel(\"scalability_atom.xlsx\", index=False)\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await calculate_latency(factoids=factoids)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-itext2kg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
